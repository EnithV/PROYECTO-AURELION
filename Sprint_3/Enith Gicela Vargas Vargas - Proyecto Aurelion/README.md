<!--
# SPRINT_3 - MACHINE LEARNING FUNDAMENTALS
**Autor:** Enith Gicela Vargas Vargas  
**Fecha:** 2025-11-11  
**Curso:** AI Fundamentals - Guayerd - IBM Skills Build  
**Sprint:** 3 - Machine Learning Fundamentals  
-->

# SPRINT_3 - MACHINE LEARNING FUNDAMENTALS

## ðŸ“‹ DescripciÃ³n General

Sprint_3 se enfoca en los fundamentos de Machine Learning, incluyendo conceptos teÃ³ricos, implementaciÃ³n prÃ¡ctica con scikit-learn, y demostraciones interactivas.

## ðŸŽ¯ Objetivos del Sprint

### Fundamentos de Machine Learning
- DefiniciÃ³n y conceptos bÃ¡sicos
- Tipos de aprendizajes (Supervisado, No Supervisado, Refuerzo)
- Algoritmos bÃ¡sicos (RegresiÃ³n, ClasificaciÃ³n, Clustering)
- MÃ©tricas de evaluaciÃ³n

### Modelado con scikit-learn
- PreparaciÃ³n de datos para ML
- DivisiÃ³n train/test
- Proceso de entrenamiento
- EvaluaciÃ³n de modelos
- Algoritmos especÃ­ficos

### Demo Interactivo
- Sistema de menÃº navegable
- EjecuciÃ³n de mÃ³dulos
- VisualizaciÃ³n de resultados

## ðŸ“ Estructura del Proyecto

```
Sprint_3/
â”œâ”€â”€ Fundamentos/           # Conceptos teÃ³ricos de ML
â”œâ”€â”€ Modelado/             # ImplementaciÃ³n prÃ¡ctica
â”œâ”€â”€ Demo/                 # Sistema interactivo
â”œâ”€â”€ resultados/           # Archivos de salida
â””â”€â”€ README.md            # Este archivo
```

## ðŸš€ Inicio RÃ¡pido

### 1. Activar entorno virtual
```bash
# Solo en Git Bash (NO PowerShell)
cd "ENITH VARGAS - PROYECTO AURELION"
source venv/Scripts/activate
```

### 2. Ejecutar demo interactivo
```bash
cd Sprint_3/Demo
python demo_interactivo.py
```

### 3. Ejecutar mÃ³dulos individuales
```bash
# Fundamentos
cd Sprint_3/Fundamentos
python 01_machine_learning_basico.py

# Modelado
cd Sprint_3/Modelado
python 01_preparacion_datos.py
```

## ðŸ“š MÃ³dulos Disponibles

### Fundamentos
- `01_machine_learning_basico.py` - Conceptos fundamentales
- `02_tipos_aprendizajes.py` - Tipos de aprendizaje
- `03_algoritmos_basicos.py` - Algoritmos principales
- `04_metricas_evaluacion.py` - MÃ©tricas de evaluaciÃ³n

### Modelado
- `01_preparacion_datos.py` - PreparaciÃ³n de datos con category_encoders
- `02_imputaciones_avanzadas.py` - Imputaciones estadÃ­sticas inteligentes
- `02_division_train_test.py` - DivisiÃ³n de conjuntos
- `03_proceso_entrenamiento.py` - Entrenamiento de modelos
- `04_evaluacion_modelos.py` - EvaluaciÃ³n de modelos
- `05_algoritmos_especificos.py` - Algoritmos especÃ­ficos

### Demo
- `demo_interactivo.py` - Sistema principal de navegaciÃ³n

## âš ï¸ Requisitos

- Python 3.8+
- Entorno virtual activado
- Dependencias instaladas (ver requirements.txt)
- **Solo usar Git Bash** (NO PowerShell)

## ðŸ”§ Dependencias

```bash
pip install pandas numpy matplotlib seaborn scikit-learn scipy category-encoders
```

## ðŸ“– DocumentaciÃ³n

Cada mÃ³dulo incluye:
- DocumentaciÃ³n completa en espaÃ±ol
- CÃ³digo en inglÃ©s (clases, funciones, variables)
- Comentarios explicativos
- Ejemplos prÃ¡cticos con datos de Aurelion

## ðŸ“š Glosario de TÃ©rminos TÃ©cnicos

### **MÃ©tricas de EvaluaciÃ³n de Modelos**

#### **RÂ² (R cuadrado o Coeficiente de DeterminaciÃ³n)**
**DefiniciÃ³n:** Medida que indica quÃ© porcentaje de la variabilidad de la variable objetivo es explicada por el modelo.

**Rango:** 0 a 1 (0% a 100%)

**InterpretaciÃ³n:**
- **RÂ² > 0.9:** Excelente capacidad predictiva
- **0.7 < RÂ² â‰¤ 0.9:** Buena capacidad predictiva
- **0.5 < RÂ² â‰¤ 0.7:** Capacidad predictiva moderada
- **RÂ² â‰¤ 0.5:** Capacidad predictiva limitada

**Ejemplo:** RÂ² = 0.85 significa que el modelo explica el 85% de la variabilidad en los datos.

---

#### **MSE (Mean Squared Error - Error CuadrÃ¡tico Medio)**
**DefiniciÃ³n:** Promedio de los cuadrados de las diferencias entre valores predichos y reales.

**CaracterÃ­sticas:**
- Penaliza mÃ¡s los errores grandes (porque eleva al cuadrado)
- Se mide en unidades al cuadrado de la variable objetivo

**InterpretaciÃ³n:** MSE bajo = errores pequeÃ±os en promedio

---

#### **RMSE (Root Mean Squared Error)**
**DefiniciÃ³n:** RaÃ­z cuadrada del MSE. Error en las mismas unidades que la variable objetivo.

**Ventaja:** MÃ¡s interpretable que MSE porque estÃ¡ en las mismas unidades.

**Ejemplo:** RMSE = $50 significa que, en promedio, las predicciones se desvÃ­an $50 del valor real.

---

#### **MAE (Mean Absolute Error - Error Absoluto Medio)**
**DefiniciÃ³n:** Promedio de las diferencias absolutas entre valores predichos y reales.

**CaracterÃ­sticas:**
- Trata todos los errores por igual
- Menos sensible a outliers que RMSE

**Ejemplo:** MAE = $30 significa que, en promedio, las predicciones se desvÃ­an $30 del valor real.

---

#### **Accuracy (PrecisiÃ³n o Exactitud)**
**DefiniciÃ³n:** ProporciÃ³n de predicciones correctas sobre el total.

**Rango:** 0 a 1 (0% a 100%)

**InterpretaciÃ³n:**
- **Accuracy = 0.95:** El 95% de las predicciones son correctas
- Puede ser engaÃ±osa cuando las clases estÃ¡n desbalanceadas

---

#### **Precision (PrecisiÃ³n)**
**DefiniciÃ³n:** De todas las predicciones positivas, Â¿cuÃ¡ntas fueron realmente positivas?

**InterpretaciÃ³n:** Precision alta = cuando el modelo predice una clase, generalmente tiene razÃ³n

---

#### **Recall (Sensibilidad)**
**DefiniciÃ³n:** De todos los casos realmente positivos, Â¿cuÃ¡ntos logrÃ³ identificar el modelo?

**InterpretaciÃ³n:** Recall alto = el modelo encuentra la mayorÃ­a de los casos positivos

---

#### **F1-Score**
**DefiniciÃ³n:** Media armÃ³nica entre Precision y Recall. Balancea ambas mÃ©tricas.

**Ventaja:** Ãštil cuando necesitas balancear Precision y Recall

---

### **Conceptos de Machine Learning**

#### **Train/Test Split (DivisiÃ³n Entrenamiento/Prueba)**
**DefiniciÃ³n:** DivisiÃ³n de los datos en dos conjuntos: uno para entrenar el modelo y otro para evaluar su rendimiento.

**PropÃ³sito:** Evaluar quÃ© tan bien el modelo generaliza a datos nuevos que no ha visto durante el entrenamiento.

**ProporciÃ³n tÃ­pica:** 70-80% para entrenamiento, 20-30% para prueba

---

#### **Cross-Validation (ValidaciÃ³n Cruzada)**
**DefiniciÃ³n:** TÃ©cnica que divide los datos en mÃºltiples subconjuntos (folds) y entrena/evalÃºa el modelo mÃºltiples veces.

**Ventaja:** Proporciona una estimaciÃ³n mÃ¡s robusta del rendimiento del modelo

---

#### **Overfitting (Sobreajuste)**
**DefiniciÃ³n:** Cuando el modelo se ajusta demasiado a los datos de entrenamiento y no generaliza bien a datos nuevos.

**SÃ­ntomas:** RÂ² alto en entrenamiento pero bajo en prueba

---

#### **Underfitting (Subajuste)**
**DefiniciÃ³n:** Cuando el modelo es demasiado simple y no captura los patrones en los datos.

**SÃ­ntomas:** RÂ² bajo tanto en entrenamiento como en prueba

---

#### **Feature Scaling (Escalado de CaracterÃ­sticas)**
**DefiniciÃ³n:** Proceso de normalizar variables a una escala comÃºn.

**Tipos:**
- **Min-Max:** Escala a rango [0, 1]
- **Z-score:** Transforma a media 0 y desviaciÃ³n estÃ¡ndar 1

**Importancia:** Algunos algoritmos (SVM, K-Means) son sensibles a la escala

---

#### **Hyperparameters (HiperparÃ¡metros)**
**DefiniciÃ³n:** ParÃ¡metros del modelo que se configuran antes del entrenamiento (no se aprenden de los datos).

**Ejemplos:** NÃºmero de Ã¡rboles en Random Forest, profundidad mÃ¡xima, tasa de aprendizaje

---

### **Algoritmos Comunes**

#### **Linear Regression (RegresiÃ³n Lineal)**
**DefiniciÃ³n:** Modelo que encuentra una lÃ­nea recta que mejor se ajusta a los datos.

**Uso:** PredicciÃ³n de valores continuos (precios, ventas, etc.)

---

#### **Random Forest**
**DefiniciÃ³n:** Algoritmo de ensemble que combina mÃºltiples Ã¡rboles de decisiÃ³n.

**Ventajas:** Robusto, maneja relaciones no lineales, proporciona importancia de variables

---

#### **SVR (Support Vector Regression)**
**DefiniciÃ³n:** VersiÃ³n de regresiÃ³n de Support Vector Machines.

**CaracterÃ­sticas:** Efectivo para datos no lineales, sensible a la escala

---

#### **Logistic Regression (RegresiÃ³n LogÃ­stica)**
**DefiniciÃ³n:** Modelo para clasificaciÃ³n binaria o multiclase.

**Uso:** PredicciÃ³n de categorÃ­as (sÃ­/no, clase A/B/C, etc.)

---

#### **K-Means Clustering**
**DefiniciÃ³n:** Algoritmo no supervisado que agrupa datos en K grupos.

**Uso:** SegmentaciÃ³n de clientes, identificaciÃ³n de patrones

---

**Nota:** Para explicaciones mÃ¡s detalladas de tÃ©rminos estadÃ­sticos (skewness, kurtosis, correlaciÃ³n de Pearson), consulta el glosario completo en `Sprint_2/Enith Gicela Vargas Vargas - Proyecto Aurelion/resultados/histogramas/ANALISIS_GRAFICOS.md`.

**Nota:** Este archivo se genera automÃ¡ticamente con datos reales del proyecto cada vez que se ejecutan las visualizaciones avanzadas en Sprint_2.

## ðŸŽ“ Resultados Esperados

Al completar Sprint_3, el estudiante habrÃ¡:
- Comprendido los fundamentos de Machine Learning
- Implementado algoritmos bÃ¡sicos con scikit-learn
- Evaluado modelos usando mÃ©tricas apropiadas
- Creado un sistema interactivo funcional

---

*Proyecto desarrollado como parte del curso AI Fundamentals de Guayerd e IBM Skills Build*
