# DEMO ASINCR√ìNICA - DESARROLLO DEL MODELO - PROYECTO AURELION

**Autor:** Enith Gicela Vargas Vargas  
**Camada:** 1  
**Grupo:** 11  
**Curso:** AI Fundamentals - Guayerd - IBM Skills Build  
**Fecha:** Noviembre 2025  
**Proyecto:** Aurelion - Demo Asincr√≥nica  
**M√≥dulo:** Presentaci√≥n del Desarrollo del Modelo

---

## üìã INTRODUCCI√ìN

Este documento presenta de manera estructurada el proceso completo de desarrollo del modelo de Machine Learning, siguiendo los 10 pasos fundamentales del desarrollo de modelos:

1. Objetivo del modelo
2. Descripci√≥n del dataset (X e y)
3. Preprocesamiento
4. Divisi√≥n Train/Test
5. Selecci√≥n del algoritmo elegido
6. Entrenamiento del modelo (.fit())
7. Predicciones (.predict())
8. M√©tricas de evaluaci√≥n
9. Modelo final implementado
10. Gr√°ficos y conclusiones

---

## 1Ô∏è‚É£ OBJETIVO DEL MODELO

### OBJETIVO PRINCIPAL

Desarrollar modelos de Machine Learning para predecir y analizar el comportamiento de ventas en la Tienda Aurelion.

### OBJETIVOS ESPEC√çFICOS

#### üìä REGRESI√ìN

- **Objetivo:** Predecir el importe de ventas bas√°ndose en caracter√≠sticas como cantidad, precio unitario, categor√≠a, medio de pago, etc.
- **Modelo:** Random Forest Regressor
- **M√©trica objetivo:** R¬≤ > 0.95 (95% de variabilidad explicada)
- **Resultado obtenido:** R¬≤ = 0.9962 (99.62%) ‚≠ê Excelente

#### üéØ CLASIFICACI√ìN

- **Objetivo:** Clasificar clientes en segmentos (Bajo, Medio, Alto) seg√∫n su comportamiento de compra
- **Modelo:** SVC / Logistic Regression
- **M√©trica objetivo:** Accuracy > 0.85 (85% de precisi√≥n)
- **Resultado obtenido:** Accuracy = 0.8841 (88.41%) ‚≠ê Muy bueno

#### üîç CLUSTERING

- **Objetivo:** Agrupar transacciones similares para identificar patrones de comportamiento
- **Modelo:** K-Means Clustering
- **Objetivo:** Identificar 3 grupos naturales de transacciones
- **Resultado obtenido:** 3 clusters identificados, Silhouette Score = 0.39

---

## 2Ô∏è‚É£ DESCRIPCI√ìN DEL DATASET (X e y)

### üìä ESTRUCTURA DEL DATASET

- **Total de registros:** 343 l√≠neas de detalle
- **Clientes √∫nicos:** 100 clientes
- **Productos √∫nicos:** 100 productos
- **Ventas √∫nicas:** 120 transacciones

### üìã VARIABLES PREDICTORAS (X - Features)

#### Variables Num√©ricas:

- **cantidad:** Cantidad de productos por l√≠nea de venta (rango: 1-5)
- **precio_unitario_detalle:** Precio unitario del producto
- **importe:** Importe total de la l√≠nea (variable objetivo para regresi√≥n)
- **edad_cliente:** Edad del cliente

#### Variables Categ√≥ricas (codificadas):

- **categoria:** Categor√≠a del producto (Alimentos, Limpieza)
- **medio_pago:** M√©todo de pago (efectivo, tarjeta, qr, transferencia)
- **ciudad:** Ciudad del cliente (6 ciudades diferentes: Carlos Paz, Rio Cuarto, C√≥rdoba, Villa Mar√≠a, Alta Gracia, Mendiolaza)
- **genero_cliente:** G√©nero del cliente

### üéØ VARIABLES OBJETIVO (y - Target)

#### Para REGRESI√ìN:

- **y = importe** (variable continua)
- **Objetivo:** Predecir el importe de una venta
- **Rango:** $272 - $20,345 pesos argentinos

#### Para CLASIFICACI√ìN:

- **y = segmento_cliente** (variable categ√≥rica: Bajo, Medio, Alto)
- **Objetivo:** Clasificar clientes en segmentos seg√∫n su comportamiento de compra
- **Distribuci√≥n:** Aproximadamente 33% Bajo, 33% Medio, 33% Alto

#### Para CLUSTERING:

- **No hay variable objetivo** (aprendizaje no supervisado)
- **Features utilizadas:** cantidad, precio_unitario_detalle, importe

### üìê DIMENSIONES FINALES

- **Dataset final:** 343 registros √ó 27 columnas
- **Features (X):** ~12-15 variables predictoras
- **Target (y):** 1 variable objetivo (seg√∫n el tipo de problema)

---

## 3Ô∏è‚É£ PREPROCESAMIENTO

### üîß T√âCNICAS APLICADAS

#### 1. IMPUTACI√ìN DE VALORES FALTANTES

- **Mediana:** Para distribuciones sesgadas (skewness > 1)
- **Media:** Para distribuciones normales (skewness ‚â§ 1)
- **Moda:** Para variables categ√≥ricas
- **Resultado:** 0 valores nulos (100% completitud)

#### 2. TRATAMIENTO DE OUTLIERS

- **M√©todo:** Winsorization (limitaci√≥n a percentiles 5 y 95)
- **Outliers detectados:** 7 en variable 'importe' (2.0%)
- **Resultado:** Outliers tratados sin p√©rdida de informaci√≥n
- **Beneficio:** Distribuci√≥n m√°s estable, modelos m√°s robustos

#### 3. NORMALIZACI√ìN DE VARIABLES NUM√âRICAS

- **StandardScaler:** Para 'importe' (media=0, std=1)
  - Rango original: $272 - $20,345
  - Rango normalizado: -1.44 a 2.45
- **MinMaxScaler:** Para 'cantidad' y 'precio_unitario' (rango [0,1])
  - cantidad: 1-5 ‚Üí 0.0-1.0
  - precio_unitario: $272-$4,982 ‚Üí 0.0-1.0
- **Selecci√≥n autom√°tica:** Basada en skewness de cada variable

#### 4. CODIFICACI√ìN DE VARIABLES CATEG√ìRICAS

- **OneHot Encoding:**
  - categoria: 2 columnas (categoria_Alimentos, categoria_Limpieza)
  - medio_pago: 4 columnas (medio_pago_efectivo, medio_pago_tarjeta, medio_pago_qr, medio_pago_transferencia)
- **Binary Encoding:**
  - ciudad: 6 categor√≠as codificadas de forma compacta
- **Resultado:** Todas las variables son num√©ricas (listas para ML)

#### 5. MERGE DE TABLAS

- **M√©todo:** LEFT JOIN entre ventas, clientes, productos y detalle_ventas
- **Validaci√≥n:** Integridad referencial verificada (0 registros hu√©rfanos)
- **Resultado:** Dataset unificado con 343 registros √ó 27 columnas

### ‚úÖ RESULTADO FINAL DEL PREPROCESAMIENTO

- ‚úÖ Dataset completamente limpio y normalizado
- ‚úÖ 0 valores nulos (100% completitud)
- ‚úÖ Todas las variables en escalas comparables
- ‚úÖ Outliers tratados adecuadamente
- ‚úÖ Variables categ√≥ricas codificadas
- ‚úÖ Listo para Machine Learning

---

## 4Ô∏è‚É£ DIVISI√ìN TRAIN/TEST

### üìä M√âTODO UTILIZADO: Holdout Method (M√©todo de Retenci√≥n)

#### üîß IMPLEMENTACI√ìN

- **Funci√≥n:** `train_test_split()` de scikit-learn
- **Proporci√≥n:** 80% entrenamiento / 20% prueba
- **random_state:** 42 (para reproducibilidad)
- **Estratificaci√≥n:** S√≠ (para clasificaci√≥n, mantiene proporciones de clases)

#### üìê DIVISI√ìN DE DATOS

- **Total de registros:** 343
- **Conjunto de Entrenamiento (Train):**
  - X_train: 274 registros (80%)
  - y_train: 274 registros (80%)
- **Conjunto de Prueba (Test/Holdout):**
  - X_test: 69 registros (20%)
  - y_test: 69 registros (20%)

#### üéØ PROP√ìSITO

- **Train:** Entrenar el modelo (ajustar par√°metros)
- **Test:** Evaluar la generalizaci√≥n (datos nunca vistos durante el entrenamiento)

#### ‚úÖ VALIDACI√ìN ADICIONAL

- **K-Fold Cross-Validation (K=5):** Para validaci√≥n robusta
- **5 divisiones diferentes:** Para mayor confiabilidad
- **Resultado:** R¬≤ promedio = 0.9981 ¬± 0.0022 (muy consistente)

---

## 5Ô∏è‚É£ SELECCI√ìN DEL ALGORITMO ELEGIDO

### üîç ESTRATEGIA DE SELECCI√ìN

Se implementaron m√∫ltiples algoritmos para comparar rendimiento y seleccionar el mejor para cada tipo de problema.

### üìä ALGORITMOS PROBADOS

#### REGRESI√ìN:

1. **Linear Regression**
   - R¬≤ = 0.8499 (84.99%)
   - Modelo baseline simple e interpretable
   - Indica que hay relaciones no lineales en los datos

2. **Random Forest Regressor** ‚≠ê MEJOR
   - R¬≤ = 0.9962 (99.62%)
   - n_estimators = 100
   - Maneja relaciones no lineales y complejas
   - Proporciona importancia de caracter√≠sticas

3. **SVR (Support Vector Regression)**
   - R¬≤ = 0.9918 (99.18%)
   - Kernel RBF para relaciones no lineales
   - Maneja outliers bien

#### CLASIFICACI√ìN:

1. **Logistic Regression** ‚≠ê MEJOR
   - Accuracy = 0.8841 (88.41%)
   - max_iter = 1000, solver = 'lbfgs'
   - Interpretable, proporciona probabilidades
   - R√°pido y eficiente

2. **Random Forest Classifier**
   - Accuracy = 0.8261 (82.61%)
   - Puede sobreajustar
   - Alta precisi√≥n pero menor generalizaci√≥n

3. **SVC (Support Vector Classifier)** ‚≠ê MEJOR
   - Accuracy = 0.8841 (88.41%)
   - Igual rendimiento que Logistic Regression
   - Buena generalizaci√≥n
   - Encuentra fronteras de decisi√≥n complejas

#### CLUSTERING:

1. **K-Means** ‚≠ê ELEGIDO
   - n_clusters = 3
   - Silhouette Score = 0.39
   - Simple, r√°pido, interpretable
   - Proporciona centroides interpretables

2. **DBSCAN**
   - 5 clusters detectados autom√°ticamente
   - Detecta outliers (puntos noise)
   - No requiere especificar n√∫mero de clusters

### ‚úÖ ALGORITMO FINAL ELEGIDO

- **Regresi√≥n:** Random Forest Regressor (R¬≤ = 99.62%)
- **Clasificaci√≥n:** SVC / Logistic Regression (Accuracy = 88.41%)
- **Clustering:** K-Means (3 clusters, Silhouette = 0.39)

---

## 6Ô∏è‚É£ ENTRENAMIENTO DEL MODELO (.fit())

### üîß M√âTODO UTILIZADO: `.fit(X_train, y_train)`

#### üìù C√ìDIGO DE EJEMPLO

```python
# 1. Preparar datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 2. Crear modelo
modelo = RandomForestRegressor(
    n_estimators=100,
    random_state=42
)

# 3. Entrenar con .fit()
modelo.fit(X_train, y_train)
```

#### ‚öôÔ∏è PROCESO INTERNO DE .fit()

1. **An√°lisis de datos:**
   - El modelo analiza la relaci√≥n entre X_train e y_train
   - Identifica patrones y correlaciones

2. **C√°lculo de par√°metros:**
   - **Regresi√≥n:** Coeficientes, estructura de √°rboles, pesos
   - **Clasificaci√≥n:** Pesos, fronteras de decisi√≥n, hiperplanos
   - **Clustering:** Centroides, asignaci√≥n de clusters

3. **Optimizaci√≥n:**
   - Ajusta el modelo para minimizar el error:
     - **Regresi√≥n:** Minimiza MSE (Mean Squared Error)
     - **Clasificaci√≥n:** Minimiza Cross-Entropy Loss
   - Usa algoritmos de optimizaci√≥n (gradiente descendente, etc.)

4. **Aislamiento de datos de prueba:**
   - **Nunca** ve los datos de prueba durante este proceso
   - Solo aprende de X_train e y_train

#### üìä RESULTADOS DEL ENTRENAMIENTO

**REGRESI√ìN (Random Forest):**
- R¬≤ en entrenamiento: 0.9970 (99.70%)
- R¬≤ en prueba: 0.9962 (99.62%)
- Diferencia: 0.0008 (muy peque√±a ‚Üí no hay overfitting)
- Interpretaci√≥n: El modelo generaliza excelentemente

**CLASIFICACI√ìN (SVC/Logistic):**
- Accuracy en entrenamiento: 0.8869 (88.69%)
- Accuracy en prueba: 0.8841 (88.41%)
- Diferencia: 0.0028 (muy peque√±a ‚Üí buena generalizaci√≥n)
- Interpretaci√≥n: El modelo no memoriza, aprende patrones generales

**CLUSTERING (K-Means):**
- 3 clusters identificados
- 343 muestras distribuidas entre los 3 clusters
- Centroides calculados para cada cluster
- Shape de centroides: (3, 3) ‚Üí 3 clusters √ó 3 variables

### ‚úÖ MODELO ENTRENADO Y LISTO

- ‚úÖ Par√°metros ajustados a los datos de entrenamiento
- ‚úÖ Modelo optimizado para minimizar error
- ‚úÖ Listo para hacer predicciones con `.predict()`

---

## 7Ô∏è‚É£ PREDICCIONES (.predict())

### üîß M√âTODO UTILIZADO: `.predict(X_test)`

#### üìù C√ìDIGO DE EJEMPLO

```python
# Modelo ya entrenado con .fit()
modelo.fit(X_train, y_train)

# Hacer predicciones con .predict()
y_pred_train = modelo.predict(X_train)  # Predicciones en entrenamiento
y_pred_test = modelo.predict(X_test)    # Predicciones en prueba
```

#### ‚öôÔ∏è PROCESO INTERNO DE .predict()

1. **Recibe datos nuevos:**
   - X_test: Caracter√≠sticas de datos que el modelo nunca ha visto
   - No necesita y (la respuesta) porque el modelo la va a predecir

2. **Aplica modelo entrenado:**
   - Usa los par√°metros aprendidos durante `.fit()`
   - Aplica las reglas/patrones aprendidos a los nuevos datos
   - Genera predicciones basadas en lo aprendido

3. **Genera predicciones:**
   - y_pred: Predicciones del modelo para los nuevos datos
   - Formato: Array de predicciones (una por cada registro en X_test)

#### üìä EJEMPLO DE PREDICCI√ìN EN AURELION

**REGRESI√ìN:**
```
Input (X): 
  - cantidad = 4
  - precio_unitario = 2500
  - categoria = 'Alimentos'
  - medio_pago = 'tarjeta'
  - ciudad = 'C√≥rdoba'
  - ...

Output (y_pred): 
  - importe_predicho = $10,000

Comparaci√≥n: 
  - importe_real = $9,800
  - Error = $200 (2% de error)
```

**CLASIFICACI√ìN:**
```
Input (X): 
  - Caracter√≠sticas del cliente (edad, g√©nero, ciudad, historial)

Output (y_pred): 
  - segmento_predicho = 'Alto'

Comparaci√≥n: 
  - segmento_real = 'Alto'
  - Resultado: ‚úÖ Predicci√≥n correcta
```

**CLUSTERING:**
```
Input (X): 
  - cantidad = 3
  - precio_unitario_detalle = 2000
  - importe = 6000

Output (y_pred): 
  - cluster = 2

Interpretaci√≥n: 
  - Transacci√≥n pertenece al cluster 2
  - Similar a otras transacciones del mismo cluster
```

#### üìà USO DE PREDICCIONES

- **Evaluar rendimiento:** Comparar predicciones con valores reales
- **Calcular m√©tricas:** Accuracy, R¬≤, Precision, Recall, etc.
- **Visualizar resultados:** Gr√°ficos de predicciones vs reales
- **Producci√≥n:** Hacer predicciones sobre datos nuevos en tiempo real

---

## 8Ô∏è‚É£ M√âTRICAS DE EVALUACI√ìN

### üìä M√âTRICAS PARA REGRESI√ìN

#### 1. R¬≤ (Coeficiente de Determinaci√≥n)

- **F√≥rmula:** R¬≤ = 1 - (SS_res / SS_tot)
  - SS_res = Œ£(y_real - y_pred)¬≤ (suma de errores al cuadrado)
  - SS_tot = Œ£(y_real - y_promedio)¬≤ (suma de diferencias respecto al promedio)
- **Rango:** -‚àû a 1 (ideal: 1.0)
- **Interpretaci√≥n:** % de varianza explicada por el modelo
- **Resultado:** R¬≤ = 0.9962 (99.62%) ‚≠ê Excelente
- **Significado:** El modelo explica el 99.62% de la variabilidad en los importes

#### 2. MSE (Mean Squared Error)

- **F√≥rmula:** MSE = (1/n) √ó Œ£(y_real - y_pred)¬≤
- **Interpretaci√≥n:** Error promedio al cuadrado
- **Caracter√≠sticas:** Penaliza m√°s los errores grandes
- **Resultado:** MSE muy bajo (errores peque√±os)

#### 3. RMSE (Root Mean Squared Error)

- **F√≥rmula:** RMSE = ‚àöMSE
- **Interpretaci√≥n:** Error promedio en unidades originales
- **Ventaja:** M√°s interpretable que MSE (mismas unidades que la variable objetivo)

#### 4. MAE (Mean Absolute Error)

- **F√≥rmula:** MAE = (1/n) √ó Œ£|y_real - y_pred|
- **Interpretaci√≥n:** Error promedio absoluto
- **Ventaja:** Menos sensible a outliers que RMSE

#### 5. Cross-Validation (K-Fold CV, K=5)

- **R¬≤ promedio:** 0.9981
- **Desviaci√≥n est√°ndar:** ¬±0.0022
- **Interpretaci√≥n:** Modelo muy consistente en diferentes divisiones
- **Significado:** El rendimiento es estable y confiable

### üìä M√âTRICAS PARA CLASIFICACI√ìN

#### 1. Accuracy (Precisi√≥n Global)

- **F√≥rmula:** Accuracy = (TP + TN) / (TP + TN + FP + FN)
- **Interpretaci√≥n:** % de predicciones correctas sobre el total
- **Resultado:** 0.8841 (88.41%) ‚≠ê Muy bueno
- **Significado:** De cada 100 predicciones, 88 son correctas

#### 2. Precision (Precisi√≥n por Clase)

- **F√≥rmula:** Precision = TP / (TP + FP)
- **Interpretaci√≥n:** De las predicciones positivas, cu√°ntas son correctas
- **Resultado:** ~0.89 (89%)
- **Ejemplo:** Cuando el modelo predice "Alto", tiene raz√≥n el 89% de las veces

#### 3. Recall (Sensibilidad)

- **F√≥rmula:** Recall = TP / (TP + FN)
- **Interpretaci√≥n:** De los casos reales, cu√°ntos se detectaron
- **Resultado:** ~0.83 (83%)
- **Ejemplo:** De todos los clientes realmente "Alto", el modelo detecta el 83%

#### 4. F1-Score

- **F√≥rmula:** F1-Score = 2 √ó (Precision √ó Recall) / (Precision + Recall)
- **Interpretaci√≥n:** Balance entre Precision y Recall
- **Resultado:** ~0.86 (86%)
- **Uso:** √ötil cuando necesitas balancear ambas m√©tricas

#### 5. Matriz de Confusi√≥n

```
                    Predicci√≥n del Modelo
                  Bajo  Medio  Alto    Total Real
Valor    Bajo     28     2     0        30
Real     Medio     3    29     3        35
         Alto      0     4    31        35
```

- **Diagonal:** Predicciones correctas (88 de 100)
- **Fuera de diagonal:** Errores de clasificaci√≥n
- **Interpretaci√≥n:** Muestra exactamente d√≥nde se equivoca el modelo

### üìä M√âTRICAS PARA CLUSTERING

#### 1. Silhouette Score

- **Rango:** -1 a 1 (ideal: cercano a 1)
- **Resultado:** 0.39 ‚≠ê Aceptable
- **Interpretaci√≥n:** Clusters moderadamente bien definidos
- **Significado:** Los puntos dentro de cada cluster son similares entre s√≠

#### 2. N√∫mero de Clusters

- **K-Means:** 3 clusters identificados
- **DBSCAN:** 5 clusters detectados autom√°ticamente
- **Muestras:** 343 muestras distribuidas entre los clusters
- **Centroides:** 3 centroides generados (uno por cada cluster)

### ‚úÖ EVALUACI√ìN GENERAL

- ‚úÖ **Regresi√≥n:** Excelente (R¬≤ = 99.62%)
- ‚úÖ **Clasificaci√≥n:** Muy buena (Accuracy = 88.41%)
- ‚úÖ **Clustering:** Aceptable (Silhouette = 0.39)
- ‚úÖ **No hay overfitting:** Train ‚âà Test (diferencia < 0.01)
- ‚úÖ **Modelo generaliza bien:** Funciona bien en datos nuevos

---

## 9Ô∏è‚É£ MODELO FINAL IMPLEMENTADO

### ‚úÖ MODELOS FINALES SELECCIONADOS

#### üìä REGRESI√ìN - Random Forest Regressor

```python
from sklearn.ensemble import RandomForestRegressor

modelo_regresion = RandomForestRegressor(
    n_estimators=100,      # 100 √°rboles
    random_state=42,       # Reproducibilidad
    max_depth=None,        # Sin l√≠mite de profundidad
    min_samples_split=2,   # M√≠nimo de muestras para dividir
    min_samples_leaf=1     # M√≠nimo de muestras en hoja
)

# Entrenar
modelo_regresion.fit(X_train, y_train)

# Predecir
y_pred = modelo_regresion.predict(X_test)
```

**Caracter√≠sticas:**
- R¬≤ = 0.9962 (99.62%)
- MSE muy bajo
- Generaliza excelentemente
- Proporciona importancia de caracter√≠sticas

#### üéØ CLASIFICACI√ìN - SVC / Logistic Regression

**Opci√≥n 1: SVC**
```python
from sklearn.svm import SVC

modelo_clasificacion = SVC(random_state=42)

# Entrenar
modelo_clasificacion.fit(X_train, y_train)

# Predecir
y_pred = modelo_clasificacion.predict(X_test)
```

**Opci√≥n 2: Logistic Regression**
```python
from sklearn.linear_model import LogisticRegression

modelo_clasificacion = LogisticRegression(
    random_state=42,
    max_iter=1000,
    solver='lbfgs'
)

# Entrenar
modelo_clasificacion.fit(X_train, y_train)

# Predecir
y_pred = modelo_clasificacion.predict(X_test)
```

**Caracter√≠sticas:**
- Accuracy = 0.8841 (88.41%)
- Precision = ~0.89 (89%)
- Recall = ~0.83 (83%)
- Ambos modelos tienen el mismo rendimiento

#### üîç CLUSTERING - K-Means

```python
from sklearn.cluster import KMeans

modelo_clustering = KMeans(
    n_clusters=3,          # 3 grupos
    random_state=42,       # Reproducibilidad
    n_init=10              # 10 inicializaciones
)

# Entrenar y predecir
clusters = modelo_clustering.fit_predict(X)
```

**Caracter√≠sticas:**
- 3 clusters identificados
- Silhouette Score = 0.39
- Centroides calculados para cada cluster
- 343 muestras distribuidas entre los 3 clusters

### üíæ GUARDADO DE MODELOS

- **Formato:** .pkl (pickle)
- **Ubicaci√≥n:** `resultados/modelos/`
- **Ventaja:** Permite reutilizar modelos sin reentrenar
- **Uso:** Cargar modelos guardados para hacer predicciones en producci√≥n

---

## üîü GR√ÅFICOS Y CONCLUSIONES

### üìä VISUALIZACIONES GENERADAS

#### 1. COMPARACI√ìN DE MODELOS

- Gr√°ficos de barras comparando R¬≤/Accuracy entre modelos
- Visualizaci√≥n de m√©tricas train vs test
- Identificaci√≥n del mejor modelo

#### 2. PREDICCIONES VS VALORES REALES

- Scatter plots: y_pred vs y_real
- L√≠nea de regresi√≥n perfecta (y=x)
- Distribuci√≥n de errores
- An√°lisis de residuos

#### 3. MATRICES DE CONFUSI√ìN

- Heatmaps mostrando predicciones correctas/incorrectas
- An√°lisis por clase (Bajo, Medio, Alto)
- Visualizaci√≥n de errores de clasificaci√≥n

#### 4. CLUSTERING

- Visualizaci√≥n 2D/3D de clusters
- Centroides marcados
- Distribuci√≥n de muestras por cluster
- An√°lisis de caracter√≠sticas por cluster

#### 5. IMPORTANCIA DE CARACTER√çSTICAS

- Feature importance de Random Forest
- Variables m√°s relevantes para las predicciones
- An√°lisis de contribuci√≥n de cada variable

#### 6. DISTRIBUCI√ìN DE ERRORES

- Histogramas de residuos
- An√°lisis de outliers en predicciones
- Distribuci√≥n normal de errores

#### 7. VALIDACI√ìN CRUZADA

- Scores por fold
- Variabilidad entre divisiones
- Consistencia del modelo

### üìà TOTAL DE GR√ÅFICOS GENERADOS

**24 visualizaciones avanzadas** que incluyen:
- Comparaciones de modelos
- An√°lisis de predicciones
- Visualizaciones de clustering
- Matrices de confusi√≥n
- Distribuciones y correlaciones

---

## üìù CONCLUSIONES

### ‚úÖ LOGROS PRINCIPALES

#### 1. MODELOS DE ALTA CALIDAD

- **Regresi√≥n:** R¬≤ = 99.62% (excelente)
  - El modelo explica casi toda la variabilidad en los importes
  - Errores muy peque√±os en las predicciones
  
- **Clasificaci√≥n:** Accuracy = 88.41% (muy bueno)
  - Alta precisi√≥n en la segmentaci√≥n de clientes
  - Balance adecuado entre Precision y Recall
  
- **Clustering:** 3 grupos bien definidos
  - Identificaci√≥n de patrones de comportamiento
  - Centroides interpretables

#### 2. PREPROCESAMIENTO EXITOSO

- ‚úÖ 0 valores nulos (100% completitud)
- ‚úÖ Outliers tratados adecuadamente (Winsorization)
- ‚úÖ Variables normalizadas y codificadas
- ‚úÖ Dataset listo para Machine Learning

#### 3. GENERALIZACI√ìN EXCELENTE

- ‚úÖ Train y test tienen rendimiento similar
- ‚úÖ Diferencia < 0.01 entre train y test
- ‚úÖ No hay overfitting
- ‚úÖ Modelo funciona bien en datos nuevos

#### 4. VALIDACI√ìN ROBUSTA

- ‚úÖ Holdout method (80/20)
- ‚úÖ K-Fold Cross-Validation (K=5)
- ‚úÖ Resultados consistentes (desviaci√≥n est√°ndar baja)
- ‚úÖ Confianza alta en el rendimiento del modelo

### üéØ APLICACIONES PR√ÅCTICAS

#### PREDICCI√ìN DE VENTAS

- Predecir importe de ventas futuras
- Optimizar inventario bas√°ndose en predicciones
- Planificar estrategias de precios
- Identificar oportunidades de crecimiento

#### SEGMENTACI√ìN DE CLIENTES

- Identificar clientes de alto valor
- Personalizar campa√±as de marketing
- Mejorar retenci√≥n de clientes
- Optimizar estrategias de fidelizaci√≥n

#### AN√ÅLISIS DE PATRONES

- Identificar grupos de transacciones similares
- Detectar comportamientos an√≥malos
- Optimizar mix de productos
- Entender preferencias de clientes

### üìä IMPACTO EN EL NEGOCIO

- ‚úÖ **Mejora en la toma de decisiones:** Basada en datos y predicciones confiables
- ‚úÖ **Optimizaci√≥n de recursos:** Asignaci√≥n m√°s eficiente de inventario y marketing
- ‚úÖ **Mayor comprensi√≥n:** Del comportamiento del cliente y patrones de venta
- ‚úÖ **Base s√≥lida:** Para implementaci√≥n en producci√≥n
- ‚úÖ **Escalabilidad:** Modelos listos para crecer con m√°s datos

### üîÆ PR√ìXIMOS PASOS

1. **Implementaci√≥n en producci√≥n:**
   - Desplegar modelos en sistema de producci√≥n
   - Integrar con sistemas de ventas existentes

2. **Monitoreo continuo:**
   - Evaluar rendimiento en tiempo real
   - Reentrenar modelos peri√≥dicamente

3. **Mejoras futuras:**
   - Incorporar m√°s variables (temporalidad, estacionalidad)
   - Probar algoritmos m√°s avanzados
   - Optimizar hiperpar√°metros

---

## üìö REFERENCIAS Y DOCUMENTACI√ìN

- **Informe Completo:** `INFORME_PROYECTO_AURELION.md`
- **C√≥digo del Modelo:** `Sprint_2/Enith Gicela Vargas Vargas - Proyecto Aurelion/06_modelos_ml.py`
- **Demo Interactiva:** `Sprint_3/Enith Gicela Vargas Vargas - Proyecto Aurelion/demo_desarrollo_modelo.py`
- **Documentaci√≥n T√©cnica:** `Sprint_2/.../resultados/DOCUMENTACION_TECNICA.md`

---

**Proyecto desarrollado como parte del curso AI Fundamentals - Guayerd - IBM Skills Build**  
**Autor:** Enith Gicela Vargas Vargas  
**Fecha:** Noviembre 2025

